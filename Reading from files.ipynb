{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3 4 5] 6\n",
      "[1 2 3 4 5] 6\n",
      "[1 2 3 4 5] 6\n",
      "[1 2 3 4 5] 6\n",
      "[1 2 3 4 5] 6\n",
      "[1 2 3 4 5] 6\n",
      "[1 2 3 4 5] 6\n",
      "[1 2 3 4 5] 6\n",
      "[1 2 3 4 5] 6\n",
      "[1 2 3 4 5] 6\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "filename_queue = tf.train.string_input_producer([\"data/file0.csv\", \"data/file1.csv\"])\n",
    "\n",
    "reader = tf.TextLineReader()\n",
    "key, value = reader.read(filename_queue)\n",
    "\n",
    "# Default values, in case of empty columns. Also specifies the type of the\n",
    "# decoded result.\n",
    "record_defaults = [[1], [1], [1], [1], [1], [1]]\n",
    "col1, col2, col3, col4, col5, col6 = tf.decode_csv(\n",
    "    value, record_defaults=record_defaults)\n",
    "features = tf.pack([col1, col2, col3, col4, col5])\n",
    "\n",
    "with tf.Session() as sess:\n",
    "  # Start populating the filename queue.\n",
    "  coord = tf.train.Coordinator()\n",
    "  threads = tf.train.start_queue_runners(coord=coord)\n",
    "\n",
    "  for i in range(10):\n",
    "    # Retrieve a single instance:\n",
    "    example, label = sess.run([features, col6])\n",
    "    print (example, label)\n",
    "\n",
    "  coord.request_stop()\n",
    "  coord.join(threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Shape () must have rank at least 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-e0406333f9aa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexample_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0minput_pipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"data/file0.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-5-e0406333f9aa>\u001b[0m in \u001b[0;36minput_pipeline\u001b[0;34m(filenames, batch_size, num_epochs)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0minput_pipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilenames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m   filename_queue = tf.train.string_input_producer(\n\u001b[0;32m---> 10\u001b[0;31m       filenames, num_epochs=num_epochs, shuffle=True)\n\u001b[0m\u001b[1;32m     11\u001b[0m   \u001b[0mexample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_my_file_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename_queue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m   \u001b[0;31m# min_after_dequeue defines how big a buffer we will randomly sample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/tensorflow/python/training/input.py\u001b[0m in \u001b[0;36mstring_input_producer\u001b[0;34m(string_tensor, num_epochs, shuffle, seed, capacity, shared_name, name)\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0mshared_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshared_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m         \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 192\u001b[0;31m         summary_name=\"fraction_of_%d_full\" % capacity)\n\u001b[0m\u001b[1;32m    193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/tensorflow/python/training/input.py\u001b[0m in \u001b[0;36minput_producer\u001b[0;34m(input_tensor, element_shape, num_epochs, shuffle, seed, capacity, shared_name, summary_name, name)\u001b[0m\n\u001b[1;32m    135\u001b[0m                                 \u001b[0mshapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0melement_shape\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m                                 shared_name=shared_name, name=name)\n\u001b[0;32m--> 137\u001b[0;31m     \u001b[0menq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menqueue_many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minput_tensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m     \u001b[0mqueue_runner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_queue_runner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqueue_runner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mQueueRunner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0menq\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msummary_name\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/tensorflow/python/ops/data_flow_ops.py\u001b[0m in \u001b[0;36menqueue_many\u001b[0;34m(self, vals, name)\u001b[0m\n\u001b[1;32m    245\u001b[0m       \u001b[0;31m# NOTE(mrry): Not using a shape function because we need access to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m       \u001b[0;31m# the `QueueBase` object.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m       \u001b[0mbatch_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvals\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_rank_at_least\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    248\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shapes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         batch_dim = batch_dim.merge_with(\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/tensorflow/python/framework/tensor_shape.py\u001b[0m in \u001b[0;36mwith_rank_at_least\u001b[0;34m(self, rank)\u001b[0m\n\u001b[1;32m    640\u001b[0m     \"\"\"\n\u001b[1;32m    641\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndims\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndims\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mrank\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 642\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Shape %s must have rank at least %d\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrank\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    643\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    644\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Shape () must have rank at least 1"
     ]
    }
   ],
   "source": [
    "def read_my_file_format(filename_queue):\n",
    "  reader = tf.SomeReader()\n",
    "  key, record_string = reader.read(filename_queue)\n",
    "  example, label = tf.decode_csv(record_string)\n",
    "  #processed_example = some_processing(example)\n",
    "  return example, label\n",
    "\n",
    "def input_pipeline(filenames, batch_size, num_epochs=None):\n",
    "  filename_queue = tf.train.string_input_producer(\n",
    "      filenames, num_epochs=num_epochs, shuffle=True)\n",
    "  example, label = read_my_file_format(filename_queue)\n",
    "  # min_after_dequeue defines how big a buffer we will randomly sample\n",
    "  #   from -- bigger means better shuffling but slower start up and more\n",
    "  #   memory used.\n",
    "  # capacity must be larger than min_after_dequeue and the amount larger\n",
    "  #   determines the maximum we will prefetch.  Recommendation:\n",
    "  #   min_after_dequeue + (num_threads + a small safety margin) * batch_size\n",
    "  min_after_dequeue = 10000\n",
    "  capacity = min_after_dequeue + 3 * batch_size\n",
    "  example_batch, label_batch = tf.train.shuffle_batch(\n",
    "      [example, label], batch_size=batch_size, capacity=capacity,\n",
    "      min_after_dequeue=min_after_dequeue)\n",
    "  return example_batch, label_batch\n",
    "\n",
    "input_pipeline(\"data/file0.csv\", 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
